{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: redis in c:\\users\\dell\\anaconda3\\lib\\site-packages (5.1.1)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: async-timeout>=4.0.3; python_full_version < \"3.11.3\" in c:\\users\\dell\\anaconda3\\lib\\site-packages (from redis) (4.0.3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into Redis for 250000 events.\n",
      "Query execution times saved to results file.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import redis\n",
    "import time\n",
    "\n",
    "# Connect to your Redis instance\n",
    "r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "\n",
    "dataset_size = 250000\n",
    "\n",
    "# Insert CSV data into Redis\n",
    "with open('Downloads/event_management_dataset (1).csv', 'r') as file:\n",
    "    csv_data = csv.reader(file)\n",
    "\n",
    "    # Skip the header row if present\n",
    "    next(csv_data)\n",
    "\n",
    "    # Iterate over the rows and insert the data into Redis\n",
    "    for row in csv_data:\n",
    "        # Check if the row has the correct number of values\n",
    "        if len(row) != 10:\n",
    "            continue\n",
    "        \n",
    "        # Unpack the event management system fields\n",
    "        event_name, venue, payment_status, seats_booked, ticket_price, attendee_name, attendee_email, attendee_phone, registration_date, event_date = row\n",
    "\n",
    "        # Key for the event-attendee hash\n",
    "        key = f'event:{event_name}:{attendee_name}'\n",
    "\n",
    "        # Insert event-attendee data into Redis hash\n",
    "        r.hset(key, 'Event Name', event_name)\n",
    "        r.hset(key, 'Venue', venue)\n",
    "        r.hset(key, 'Payment Status', payment_status)\n",
    "        r.hset(key, 'Seats Booked', seats_booked)\n",
    "        r.hset(key, 'Ticket Price', ticket_price)\n",
    "        r.hset(key, 'Attendee Name', attendee_name)\n",
    "        r.hset(key, 'Email', attendee_email)\n",
    "        r.hset(key, 'Phone', attendee_phone)\n",
    "        r.hset(key, 'Registration Date', registration_date)\n",
    "        r.hset(key, 'Event Date', event_date)\n",
    "\n",
    "print(f\"Data loaded into Redis for {dataset_size} events.\")\n",
    "\n",
    "# Benchmarking the query performance to retrieve all keys matching 'event:*'\n",
    "query_times = []\n",
    "\n",
    "for _ in range(30):\n",
    "    pattern = 'event:*'\n",
    "    start_time = time.time()\n",
    "    keys = r.keys(pattern)  # Retrieve all keys matching the pattern\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    query_times.append(execution_time)\n",
    "\n",
    "# Write the execution times to a result file\n",
    "with open(f'results_query3_redis_event250k.txt', 'w') as result_file:\n",
    "    result_file.write(f\"Query 3 execution times: {query_times}\\n\")\n",
    "\n",
    "print(\"Query execution times saved to results file.\")\n",
    "\n",
    "# Close the Redis connection\n",
    "r.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into Redis for 500000 events.\n",
      "Query execution times saved to results file.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import redis\n",
    "import time\n",
    "\n",
    "# Connect to your Redis instance\n",
    "r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "\n",
    "dataset_size = 500000\n",
    "\n",
    "# Insert CSV data into Redis\n",
    "with open('Downloads/event_management_dataset2 (1).csv', 'r') as file:\n",
    "    csv_data = csv.reader(file)\n",
    "\n",
    "    # Skip the header row if present\n",
    "    next(csv_data)\n",
    "\n",
    "    # Iterate over the rows and insert the data into Redis\n",
    "    for row in csv_data:\n",
    "        # Check if the row has the correct number of values\n",
    "        if len(row) != 10:\n",
    "            continue\n",
    "        \n",
    "        # Unpack the event management system fields\n",
    "        event_name, venue, payment_status, seats_booked, ticket_price, attendee_name, attendee_email, attendee_phone, registration_date, event_date = row\n",
    "\n",
    "        # Key for the event-attendee hash\n",
    "        key = f'event:{event_name}:{attendee_name}'\n",
    "\n",
    "        # Insert event-attendee data into Redis hash\n",
    "        r.hset(key, 'Event Name', event_name)\n",
    "        r.hset(key, 'Venue', venue)\n",
    "        r.hset(key, 'Payment Status', payment_status)\n",
    "        r.hset(key, 'Seats Booked', seats_booked)\n",
    "        r.hset(key, 'Ticket Price', ticket_price)\n",
    "        r.hset(key, 'Attendee Name', attendee_name)\n",
    "        r.hset(key, 'Email', attendee_email)\n",
    "        r.hset(key, 'Phone', attendee_phone)\n",
    "        r.hset(key, 'Registration Date', registration_date)\n",
    "        r.hset(key, 'Event Date', event_date)\n",
    "\n",
    "print(f\"Data loaded into Redis for {dataset_size} events.\")\n",
    "\n",
    "# Benchmarking the query performance to retrieve all keys matching 'event:*'\n",
    "query_times = []\n",
    "\n",
    "for _ in range(30):\n",
    "    pattern = 'event:*'\n",
    "    start_time = time.time()\n",
    "    keys = r.keys(pattern)  # Retrieve all keys matching the pattern\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    query_times.append(execution_time)\n",
    "\n",
    "# Write the execution times to a result file\n",
    "with open(f'results_query3_redis_event500k.txt', 'w') as result_file:\n",
    "    result_file.write(f\"Query 3 execution times: {query_times}\\n\")\n",
    "\n",
    "print(\"Query execution times saved to results file.\")\n",
    "\n",
    "# Close the Redis connection\n",
    "r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into Redis for 750000 events.\n",
      "Query execution times saved to results file.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import redis\n",
    "import time\n",
    "\n",
    "# Connect to your Redis instance\n",
    "r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "\n",
    "dataset_size = 750000\n",
    "\n",
    "# Insert CSV data into Redis\n",
    "with open('Downloads/event_management_dataset3 (1).csv', 'r') as file:\n",
    "    csv_data = csv.reader(file)\n",
    "\n",
    "    # Skip the header row if present\n",
    "    next(csv_data)\n",
    "\n",
    "    # Iterate over the rows and insert the data into Redis\n",
    "    for row in csv_data:\n",
    "        # Check if the row has the correct number of values\n",
    "        if len(row) != 10:\n",
    "            continue\n",
    "        \n",
    "        # Unpack the event management system fields\n",
    "        event_name, venue, payment_status, seats_booked, ticket_price, attendee_name, attendee_email, attendee_phone, registration_date, event_date = row\n",
    "\n",
    "        # Key for the event-attendee hash\n",
    "        key = f'event:{event_name}:{attendee_name}'\n",
    "\n",
    "        # Insert event-attendee data into Redis hash\n",
    "        r.hset(key, 'Event Name', event_name)\n",
    "        r.hset(key, 'Venue', venue)\n",
    "        r.hset(key, 'Payment Status', payment_status)\n",
    "        r.hset(key, 'Seats Booked', seats_booked)\n",
    "        r.hset(key, 'Ticket Price', ticket_price)\n",
    "        r.hset(key, 'Attendee Name', attendee_name)\n",
    "        r.hset(key, 'Email', attendee_email)\n",
    "        r.hset(key, 'Phone', attendee_phone)\n",
    "        r.hset(key, 'Registration Date', registration_date)\n",
    "        r.hset(key, 'Event Date', event_date)\n",
    "\n",
    "print(f\"Data loaded into Redis for {dataset_size} events.\")\n",
    "\n",
    "# Benchmarking the query performance to retrieve all keys matching 'event:*'\n",
    "query_times = []\n",
    "\n",
    "for _ in range(30):\n",
    "    pattern = 'event:*'\n",
    "    start_time = time.time()\n",
    "    keys = r.keys(pattern)  # Retrieve all keys matching the pattern\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    query_times.append(execution_time)\n",
    "\n",
    "# Write the execution times to a result file\n",
    "with open(f'results_query3_redis_event750k.txt', 'w') as result_file:\n",
    "    result_file.write(f\"Query 3 execution times: {query_times}\\n\")\n",
    "\n",
    "print(\"Query execution times saved to results file.\")\n",
    "\n",
    "# Close the Redis connection\n",
    "r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into Redis for 1000000 events.\n",
      "Query execution times saved to results file.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import redis\n",
    "import time\n",
    "\n",
    "# Connect to your Redis instance\n",
    "r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "\n",
    "dataset_size = 1000000\n",
    "\n",
    "# Insert CSV data into Redis\n",
    "with open('Downloads/event_management_dataset4 (1).csv', 'r') as file:\n",
    "    csv_data = csv.reader(file)\n",
    "\n",
    "    # Skip the header row if present\n",
    "    next(csv_data)\n",
    "\n",
    "    # Iterate over the rows and insert the data into Redis\n",
    "    for row in csv_data:\n",
    "        # Check if the row has the correct number of values\n",
    "        if len(row) != 10:\n",
    "            continue\n",
    "        \n",
    "        # Unpack the event management system fields\n",
    "        event_name, venue, payment_status, seats_booked, ticket_price, attendee_name, attendee_email, attendee_phone, registration_date, event_date = row\n",
    "\n",
    "        # Key for the event-attendee hash\n",
    "        key = f'event:{event_name}:{attendee_name}'\n",
    "\n",
    "        # Insert event-attendee data into Redis hash\n",
    "        r.hset(key, 'Event Name', event_name)\n",
    "        r.hset(key, 'Venue', venue)\n",
    "        r.hset(key, 'Payment Status', payment_status)\n",
    "        r.hset(key, 'Seats Booked', seats_booked)\n",
    "        r.hset(key, 'Ticket Price', ticket_price)\n",
    "        r.hset(key, 'Attendee Name', attendee_name)\n",
    "        r.hset(key, 'Email', attendee_email)\n",
    "        r.hset(key, 'Phone', attendee_phone)\n",
    "        r.hset(key, 'Registration Date', registration_date)\n",
    "        r.hset(key, 'Event Date', event_date)\n",
    "\n",
    "print(f\"Data loaded into Redis for {dataset_size} events.\")\n",
    "\n",
    "# Benchmarking the query performance to retrieve all keys matching 'event:*'\n",
    "query_times = []\n",
    "\n",
    "for _ in range(30):\n",
    "    pattern = 'event:*'\n",
    "    start_time = time.time()\n",
    "    keys = r.keys(pattern)  # Retrieve all keys matching the pattern\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    query_times.append(execution_time)\n",
    "\n",
    "# Write the execution times to a result file\n",
    "with open(f'results_query3_redis_event1M.txt', 'w') as result_file:\n",
    "    result_file.write(f\"Query 3 execution times: {query_times}\\n\")\n",
    "\n",
    "print(\"Query execution times saved to results file.\")\n",
    "\n",
    "# Close the Redis connection\n",
    "r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
